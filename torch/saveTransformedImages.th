require 'image'
npy4th = require 'npy4th'
require 'data_aflw';
require 'cunn'
require 'cudnn'
require 'nn';
require 'optim'
require 'stn'
npy4th=require 'npy4th';
require 'torchx';
require 'gnuplot';
dump=require 'dump';
tps_helper=require 'tps_helper';

function createSpatialNet(tps_model_path)
    local locnet = torch.load(tps_model_path);
    local tranet=nn.Transpose({2,3},{3,4})
    local concat=nn.ConcatTable()
    concat:add(tranet)
    concat:add(locnet)

    local net=nn.Sequential();
    net:add(concat)
    net:add(nn.BilinearSamplerBHWD())

    local downGrid=nn.Sequential();
    downGrid:add(nn.Identity());

    local paranet=nn.ParallelTable();
    paranet:add(net);
    paranet:add(downGrid);

    local spanet=nn.Sequential();
    spanet:add(paranet);
    spanet:add(nn.BilinearSamplerBHWD());
    spanet:add(nn.Transpose({3,4},{2,3}));
    
    return spanet;
end

function getDownSampleGrid(batchSize)
    local out_grids_new=torch.zeros(40,40,2);
    for r=1,out_grids_new:size(1) do
        for c=1,out_grids_new:size(2) do
            out_grids_new[{r,c,1}]=-1+(1/20*r);
            out_grids_new[{r,c,2}]=-1+(1/20*c);
        end
    end
    out_grids_new=out_grids_new:view(1,out_grids_new:size(1),out_grids_new:size(2),out_grids_new:size(3));
    out_grids_new=torch.repeatTensor(out_grids_new,batchSize,1,1,1);
    return out_grids_new;
end


function main(params) 

    local data_path=params.data_path;
    local out_dir=params.outDir
    local net_file=params.model
    if params.limit<0 then
        params.limit=nil;
    end
    
    paths.mkdir(out_dir);
    cutorch.setDevice(params.gpu);

    local net=createSpatialNet(params.tps_model_path);
    ds_grid= getDownSampleGrid(params.batchSize);
    print (net);

    net = net:cuda();
    ds_grid= ds_grid:cuda();

    local data_params={file_path=data_path,
                    batch_size=params.batchSize,
                    mean_file=params.mean_im_path,
                    std_file=params.std_im_path,
                    augmentation=false,
                    limit=params.limit,
                    input_size={224,224},
                    imagenet_mean=true};

    td=data(data_params);

    for i=1,params.iterations do
        print (i);
        td:getTrainingData();
        td.training_set.data=td.training_set.data:cuda();
        local out_files = net:forward{td.training_set.data,ds_grid};
        out_files=out_files:double();
        for im_no=1,out_files:size(1) do
            local out_file_curr=paths.concat(out_dir,i..'_'..im_no..'.jpg');
            local im_curr=out_files[im_no];
            for idx_rgb=1,3 do
                im_curr[{idx_rgb,{},{}}]=im_curr[{idx_rgb,{},{}}]+td.params.imagenet_mean[idx_rgb];
            end
            im_curr=im_curr/255;
            image.save(out_file_curr,im_curr);
        end
        -- break;
    end


end


cmd = torch.CmdLine()
cmd:text()
cmd:text('Train Full network')
cmd:text()
cmd:text('Options')

local epoch_size=2;

cmd:option('-tps_model_path','/home/SSD3/maheen-data/temp/tps_train_allKP_adam_noBad_bn/final/model_all_final.dat');
-- cmd:option('-tps_model_path','/home/SSD3/maheen-data/horse_project/tps_train_allKP_adam/intermediate/model_all_14400.dat');

cmd:option('-outDir','/home/SSD3/maheen-data/temp/tps_train_allKP_adam_noBad_bn/val_transformed_im_40','directory to write output');

cmd:option('-limit',-1,'num of training data to read');
cmd:option('-iterations',1*epoch_size,'num of iterations to run');
cmd:option('-batchSize',100,'batch size');

cmd:option('-data_path','/home/SSD3/maheen-data/horse_project/data_check/horse/pairs_val.txt')
-- cmd:option('-data_path','/home/SSD3/maheen-data/horse_project/data_check/horse/pairs.txt')

cmd:option('-mean_im_path','/home/SSD3/maheen-data/data_face_network/aflw_cvpr_40_mean.png');
cmd:option('-std_im_path','/home/SSD3/maheen-data/data_face_network/aflw_cvpr_40_std.png');

cmd:option('-gpu',1,'gpu to run the training on');
cmd:text()

params = cmd:parse(arg)
main(params);
