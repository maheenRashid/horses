require 'image'
npy4th = require 'npy4th'
require 'data_aflw_optimizing';
require 'data_horseHuman_xiuye_optimizing';
require 'cunn'
require 'cudnn'
require 'nn';
require 'optim'
require 'stn'
npy4th=require 'npy4th';
require 'torchx';
require 'gnuplot';
dump=require 'dump';
tps_helper=require 'tps_helper';

visualize=require 'visualize';
loss_helper=require 'loss_helper';

function doTheForwardEuclidean(batch_inputs,batch_targets,saveImage,padTPS)
    local batch_inputs_view;
    if saveImage then
        batch_inputs_view=batch_inputs:double():clone();
    end

    local inputs;
    if ds_grid then
        inputs={batch_inputs,ds_grid:clone()}
    else
        inputs=batch_inputs;    
    end

    -- local midoutputs=net:get(1):forward(inputs);
    local midoutputs;
    if padTPS then
        local tps_output = net:get(1):get(1):get(2):forward(inputs);
        local bil_input = net:get(1):get(1):get(1):forward(inputs);
        tps_output[tps_output:le(-1)]=-1;
        tps_output[tps_output:ge(1)]=1;
        local temp=net:get(1):get(2):forward{bil_input,tps_output};
        midoutputs=net:get(1):get(3):forward(temp);
    else
        midoutputs=net:get(1):forward(inputs);
    end

    local midoutputs_view;
    if saveImage then
        midoutputs_view=midoutputs:double():clone();
    end

    midoutputs=tps_helper:switchMeans(midoutputs,td.params.imagenet_mean,td.mean_im,td.std_im)
    -- print ('mean',torch.mean(midoutputs));

    local outputs=net:get(2):forward(midoutputs);
    
    local tps_layer;
    if ds_grid then
        tps_layer= net:get(1):get(1):get(1):get(1):get(2);
        tps_layer=tps_layer:get(#tps_layer);
    else
        tps_layer= net:get(1):get(1):get(2);
        tps_layer=tps_layer:get(#tps_layer);
    end

    local t_pts=tps_helper:getPointsOriginalImage(outputs,tps_layer.output)

    if saveImage then
        -- local t_pts_copy=t_pts:clone();
        local outputs_view=outputs:view(outputs:size(1),outputs:size(2)/2,2):clone();
        local t_pts_view=t_pts:view(t_pts:size(1),t_pts:size(2)/2,2):clone();
        -- local colors={{255,0,0},{255,255,0},{0,0,255},{0,255,0},{255,0,255}};
        local colors={{0,255,0}};
        local pointSize=10;  
        -- visualize=Visualize();
        t_pts_view=t_pts_view:transpose(2,3)
        -- print (t_pts_view[1]);
        -- print (outputs_view[1]);

        -- for idx_im=1,im_all:size(1) do
        --     local out_file= file_info[1]..idx_im..file_info[2]
        --     local im_new=self:drawKeyPoints(im_all[idx_im]:clone(),pts_all[idx_im],scale,colors,pointSize);
        --     image.save(out_file,im_new);
        -- end
        for im_num=1,t_pts:size(1) do 
            local out_file_gt=saveImage..im_num..'_gt_pts.npy';
            local out_file_pred=saveImage..im_num..'_pred_pts.npy';

            local pred_output=t_pts[im_num]:clone():double();
            local gt_output=batch_targets[im_num]:clone():double();
            pred_output=pred_output:view(pred_output:size(1)/2,2);
            npy4th.savenpy(out_file_gt,gt_output);
            npy4th.savenpy(out_file_pred,pred_output);

        end

        -- visualize:saveBatchImagesWithKeypointsSensitive(batch_inputs_view,outputs_view:transpose(2,3),{saveImage,'_org.jpg'},nil,{-1,1},colors,pointSize,binary);
        -- visualize:saveBatchImagesWithKeypointsSensitive(batch_inputs_view,batch_targets[{{},{},{1,2}}]:transpose(2,3),{saveImage,'_gt.jpg'},nil,{-1,1},colors,pointSize,binary);

        local binary=batch_targets[{{},{},3}]:clone();
        visualize:saveBatchImagesWithKeypointsSensitive(batch_inputs_view,t_pts_view,{saveImage,'_org.jpg'},td.params.imagenet_mean,{-1,1},colors,pointSize,binary);
        visualize:saveBatchImagesWithKeypointsSensitive(midoutputs_view,outputs_view:transpose(2,3),{saveImage,'.jpg'},td.params.imagenet_mean,{-1,1},colors,pointSize,binary);

        visualize:saveBatchImagesWithKeypointsSensitive(batch_inputs_view,t_pts_view,{saveImage,'_org_nokp.jpg'},nil,{-1,1},colors,-1,binary);
        visualize:saveBatchImagesWithKeypointsSensitive(midoutputs_view,outputs_view:transpose(2,3),{saveImage,'_nokp.jpg'},nil,{-1,1},colors,-1,binary);
    end

    -- local dloss = loss_helper:getLossD_RCNN(t_pts,batch_targets);
    -- print (t_pts[1]);
    -- print (batch_targets[1]);
    -- print (t_pts:size(),batch_targets:size());
    local loss,loss_all = loss_helper:getLoss_Euclidean(t_pts,batch_targets);
    return loss,loss_all,midoutputs,inputs;
end


function test(params)
    local data_path=params.data_path;
    local out_dir=params.outDir
    local net_file=params.model
    if params.limit<0 then
        params.limit=nil;
    end
    val_data_path= params.val_data_path

    -- paths.mkdir(out_dir);
    local out_dir_images=params.outDirTest;
    -- paths.concat(out_dir,'test_images');
    paths.mkdir(out_dir_images);
    local out_file_loss_val=paths.concat(out_dir_images,'loss_final_val.npy');
    local out_file_loss_val_ind=paths.concat(out_dir_images,'loss_final_val_ind.npy');
    local out_file_log=paths.concat(out_dir_images,'log_test.txt');
    local logger=torch.DiskFile(out_file_log,'w');

    logger:writeString(dump.tostring(params)..'\n');
    cutorch.setDevice(params.gpu);
    logger:writeString(dump.tostring('loading network')..'\n');
    -- print ('loading network');

    net=torch.load(params.full_model_path);
    if params.full_size then
        ds_grid=nil;
    else
        ds_grid= getDownSampleGrid(params.batchSize);
    end

    logger:writeString(dump.tostring('done loading network')..'\n');
    -- print ('done loading network');
    -- logger:writeString(dump.tostring(net)..'\n');
    print (net);

    logger:writeString(dump.tostring('making cuda')..'\n');
    -- print ('making cuda');
    net = net:cuda();
    if ds_grid then
        ds_grid = ds_grid:cuda();
    end
    net:evaluate();

    logger:writeString(dump.tostring('done')..'\n');
    -- print ('done');

    logger:writeString(dump.tostring('loading params')..'\n');
    -- print ('loading params');
    parameters, gradParameters = net:getParameters()
    logger:writeString(dump.tostring('loading done')..'\n');
    -- print ('loading done');
    logger:writeString(dump.tostring(optimState)..'\n');
    -- print (optimState)

    local data_params={file_path=val_data_path,
                    batch_size=params.batchSize,
                    mean_file=params.mean_im_path,
                    std_file=params.std_im_path,
                    augmentation=false,
                    limit=params.limit,
                    input_size={224,224},
                    imagenet_mean=true};

    if params.face then
        data_params.imagenet_mean=false;
    end
    
    td=data(data_params);
   
    local val_losses = {};
    local val_losses_iter = {};

    local val_losses_ind={};

    for i=1,params.iterations do

            td:getTrainingData();

            td.training_set.data=td.training_set.data:cuda();
            td.training_set.label=td.training_set.label:cuda();

            local batch_inputs=td.training_set.data;
            local batch_targets=td.training_set.label;
            
            local loss,loss_all;
            local saveImage=paths.concat(out_dir_images,i..'_')
            -- local colors={{255,0,0},{255,255,0},{0,0,255},{0,255,0},{255,0,255}};
            local colors={{0,255,0}};
            local pointSize=10;
            if params.face then
                local outputs=net:forward(batch_inputs);
                loss,loss_all = loss_helper:getLoss_Euclidean(outputs,batch_targets);
                
                local outputs_view=outputs:view(outputs:size(1),outputs:size(2)/2,2):clone();
                local batch_inputs_view=batch_inputs:clone():double();
                batch_inputs_view=tps_helper:unMean(batch_inputs_view,td.mean_im,td.std_im);
                
                for im_num=1,outputs_view:size(1) do 
                    local out_file_gt=saveImage..im_num..'_gt_pts.npy';
                    local out_file_pred=saveImage..im_num..'_pred_pts.npy';

                    local pred_output=outputs_view[im_num]:clone():double();
                    local gt_output=batch_targets[im_num]:clone():double();
                    -- pred_output=pred_output:view(pred_output:size(1)/2,2);
                    npy4th.savenpy(out_file_gt,gt_output);
                    npy4th.savenpy(out_file_pred,pred_output);
                end
                local binary=batch_targets[{{},{},3}]:clone();
                -- binary=binary:view(binary:size(1),5);
                visualize:saveBatchImagesWithKeypointsSensitive(batch_inputs_view,outputs_view:transpose(2,3),{saveImage,'_org.jpg'},nil,{-1,1},colors,pointSize,binary);
                visualize:saveBatchImagesWithKeypointsSensitive(batch_inputs_view,batch_targets[{{},{},{1,2}}]:transpose(2,3),{saveImage,'_gt.jpg'},nil,{-1,1},colors,pointSize,binary);

                visualize:saveBatchImagesWithKeypointsSensitive(batch_inputs_view,outputs_view:transpose(2,3),{saveImage,'_org_nokp.jpg'},nil,{-1,1},colors,-1,binary);
                -- visualize:saveBatchImagesWithKeypointsSensitive(batch_inputs_view,batch_targets[{{},{},{1,2}}]:transpose(2,3),{saveImage,'_gt_nokp.jpg'},nil,{-1,1},colors,-1,binary);
                -- visualize:saveBatchImagesWithKeypoints(batch_inputs_view,outputs_view:transpose(2,3),{saveImage,'_org.jpg'},nil,{-1,1},colors);
                -- visualize:saveBatchImagesWithKeypoints(batch_inputs_view,batch_targets[{{},{},{1,2}}]:transpose(2,3),{saveImage,'_gt.jpg'},nil,{-1,1},colors);
            else
                loss,loss_all = doTheForwardEuclidean(batch_inputs,batch_targets,saveImage,params.padTPS)
            end

            for idx_ind=1,loss_all:size(1) do
                val_losses_ind[#val_losses_ind+1]=loss_all[idx_ind];
            end
            -- gradParameters:zero()
            -- local outputs=net:forward(batch_inputs);
            -- local loss = loss_helper:getLoss_RCNN(outputs,batch_targets);

            val_losses[#val_losses+1]=loss;
            val_losses_iter[#val_losses_iter+1]=i;

            -- net:training();
            disp_str=string.format("minibatches processed: %6s, val loss = %6.6f", i, val_losses[#val_losses])
            logger:writeString(dump.tostring(disp_str)..'\n');
            print(disp_str)

    end
    val_losses_ind=torch.Tensor(val_losses_ind);
    print (val_losses_ind:size())
    if val_losses_ind:size(1)>#td.lines_horse then
        val_losses_ind=val_losses_ind[{{1,#td.lines_horse}}];
    end
    print (val_losses_ind:size())
    print (params.full_model_path);
    disp_str=string.format("minibatches processed: all, val loss = %6.6f", torch.mean(val_losses_ind))
    logger:writeString(dump.tostring(disp_str)..'\n');
    print(disp_str)

    npy4th.savenpy(out_file_loss_val, torch.Tensor(val_losses))
    npy4th.savenpy(out_file_loss_val_ind, val_losses_ind)

end


cmd = torch.CmdLine()
cmd:text()
cmd:text('Train Full network')
cmd:text()
cmd:text('Options')

-- cmd:option('-outDir','temp');

cmd:option('-mean_im_path','/home/SSD3/maheen-data/data_face_network/aflw_cvpr_224_mean.png');
cmd:option('-std_im_path','/home/SSD3/maheen-data/data_face_network/aflw_cvpr_224_std.png');
cmd:option('-full_size',true,'true when on 224');

cmd:option('-limit',-1,'num of training data to read');
cmd:option('-batchSize',64,'batch size');

cmd:option('-mean_im_path','/home/SSD3/maheen-data/data_face_network/aflw_cvpr_224_mean.png');
cmd:option('-std_im_path','/home/SSD3/maheen-data/data_face_network/aflw_cvpr_224_std.png');


cmd:option('-val_data_path','/home/SSD3/maheen-data/horse_project/files_for_sheepCode/sheep_test_us_sheep_minloss.txt');

cmd:option('-gpu',1,'gpu to run the training on');


cmd:option('-full_model_path','/home/SSD3/maheen-data/horse_project/full_system_sheep_data_5kp/full_system/final/model_all_final.dat');
    -- 'temp');
    -- paths.concat(params.outDir,'final/model_all_final.dat'),'full model path for testing');
    -- ,'temp');
cmd:option('-iterations',2,'num of iterations to run');
cmd:option('-batchSize',50,'batch size');
cmd:option('-outDirTest','/home/SSD3/maheen-data/horse_project/sheep_baseline_results/sheep_us/test_images');
cmd:option('-face',false);
    -- paths.concat(params.outDir,'test_images'));
    -- 'temp');
params = cmd:parse(arg)
print (params.full_model_path);
test(params)