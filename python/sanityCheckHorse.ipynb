{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "(4096, 4096)\n",
      "0.0 1.9060927888\n"
     ]
    }
   ],
   "source": [
    "import util;\n",
    "import numpy as np;\n",
    "import visualize;\n",
    "# import sklearn;\n",
    "import os;\n",
    "import time;\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def getDataAndLabels(data_path,batchSize,numBatches,fc6_dir):\n",
    "    lines=util.readLinesFromFile(data_path);\n",
    "    out_data=np.zeros((len(lines),4096));\n",
    "    start_curr=0;\n",
    "    for i in range(numBatches):\n",
    "        file_curr=os.path.join(fc6_dir,str(i+1)+'.npy');\n",
    "        fc6_curr=np.load(file_curr);\n",
    "        end_curr=min(start_curr+fc6_curr.shape[0],len(lines));\n",
    "        len_curr=end_curr-start_curr\n",
    "        out_data[start_curr:end_curr,:]=fc6_curr[:len_curr];\n",
    "        start_curr=end_curr;\n",
    "    return out_data,lines;\n",
    "\n",
    "def normalizeData(data):\n",
    "    norm_data=np.linalg.norm(data,axis=1);\n",
    "    norm_data=np.expand_dims(norm_data,axis=1);\n",
    "    norm_data=np.tile(norm_data,(1,data.shape[1]));\n",
    "    data=data/norm_data;\n",
    "    return data;\n",
    "\n",
    "def getClusterIdx(data,num_clusters):\n",
    "#     norm_data=np.linalg.norm(data,axis=1);\n",
    "#     norm_data=np.expand_dims(norm_data,axis=1);\n",
    "#     norm_data=np.tile(norm_data,(1,data.shape[1]));\n",
    "#     data=data/norm_data;\n",
    "    data=normalizeData(data)\n",
    "    kmeaner=KMeans(n_clusters=num_clusters,n_jobs=12);\n",
    "    cluster_idx=kmeaner.fit_predict(data);\n",
    "    return cluster_idx;\n",
    "\n",
    "def saveClusterIdx(data_path,batchSize,numBatches,fc6_dir,num_clusters,out_file_clusters):\n",
    "    data,labels = getDataAndLabels(data_path,batchSize,numBatches,fc6_dir);\n",
    "    cluster_idx = getClusterIdx(data,num_clusters);\n",
    "    print out_file_clusters,cluster_idx.shape\n",
    "    np.save(out_file_clusters,cluster_idx);\n",
    "\n",
    "def makeClusterHTML(out_file_html,labels,num_cols,size_im,dir_server):\n",
    "    ims=[];\n",
    "    captions=[];\n",
    "    start_idx=0;\n",
    "    while start_idx<len(labels):\n",
    "        row_curr=[];\n",
    "        caption_curr=[];\n",
    "        if start_idx+num_cols>len(labels):\n",
    "            num_cols_real=len(labels)-start_idx;\n",
    "        else:\n",
    "            num_cols_real=num_cols;\n",
    "        for col_no in range(num_cols_real):\n",
    "            idx_curr=start_idx+col_no;\n",
    "            label_curr=labels[idx_curr];\n",
    "            row_curr.append(util.getRelPath(label_curr,dir_server));\n",
    "            caption_curr.append('');\n",
    "        ims.append(row_curr);\n",
    "        captions.append(caption_curr);\n",
    "        start_idx=start_idx+num_cols_real;\n",
    "    visualize.writeHTML(out_file_html,ims,captions,size_im,size_im);\n",
    "    print out_file_html.replace(dir_server,'http://vision1.idav.ucdavis.edu:1000')\n",
    "\n",
    "def script_makeClusterHTML(labels,clusters,out_dir):\n",
    "    labels=np.array(labels);\n",
    "    clusters_uni=list(set(clusters));\n",
    "    labels_clusters=[];\n",
    "    for cluster_idx in clusters_uni:\n",
    "        labels_rel=labels[clusters==cluster_idx];\n",
    "        print len(labels_rel);\n",
    "        labels_clusters.append(labels_rel);\n",
    "        out_file_html=os.path.join(out_dir,str(cluster_idx)+'.html');\n",
    "        num_cols=40;\n",
    "        size_im=20;\n",
    "        makeClusterHTML(out_file_html,labels_rel,num_cols,size_im,dir_server);\n",
    "\n",
    "    \n",
    "print 'hello';\n",
    "data_path='/home/SSD3/maheen-data/horse_project/data_check/horse/pairs_all.txt';\n",
    "dir_server='/home/SSD3/maheen-data';\n",
    "out_dir='/home/SSD3/maheen-data/horse_project/sanityCheckHorse'\n",
    "batchSize=128;\n",
    "numBatches=30;\n",
    "fc6_dir=os.path.join(out_dir,'fc6');\n",
    "num_clusters=8;\n",
    "out_file_clusters=os.path.join(fc6_dir,'clusters.npy');\n",
    "# saveClusterIdx(data_path,batchSize,numBatches,fc6_dir,num_clusters,out_file_clusters);\n",
    "\n",
    "# labels=util.readLinesFromFile(data_path);\n",
    "# labels=[line_curr[:line_curr.index(' ')] for line_curr in labels];\n",
    "clusters=np.load(out_file_clusters);\n",
    "# script_makeClusterHTML(labels,clusters,out_dir)\n",
    "\n",
    "data,labels=getDataAndLabels(data_path,batchSize,numBatches,fc6_dir);\n",
    "data=normalizeData(data);\n",
    "clusters_uni=list(set(clusters));\n",
    "for cluster_idx in clusters_uni:\n",
    "    data_rel=data[clusters==cluster_idx,:];\n",
    "    labels_rel=data[clusters==cluster_idx];\n",
    "    pairwise=np.dot(data_rel,data_rel.T);\n",
    "    print pairwise.shape;\n",
    "    print np.min(pairwise),np.max(pairwise);\n",
    "    break;\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
