require 'image'
npy4th = require 'npy4th'
require 'data_horseHuman';
require 'cunn'
require 'cudnn'
require 'nn';
require 'optim'
require 'stn'
npy4th=require 'npy4th';
require 'torchx';

function saveImageAndAnno(out_file,im,label,mean,nonormalize)
	local label=label:clone();
	label=label:t();
	-- print (label)
	local im= im:clone();
	for idx_rgb=1,3 do
		im[idx_rgb]=im[idx_rgb]+mean[idx_rgb]
	end
	
	im=im/255;

	if not nonormalize then
		local half_r=im:size(2)/2;
		local half_c=im:size(3)/2;
		label[{1,{}}]= (label[{1,{}}]*half_r)+half_r;
		label[{2,{}}]= (label[{2,{}}]*half_c)+half_c;
	end
	
	colors={{255,0,0},{255,255,0},{0,0,255},{0,255,0},{255,0,255}}

	for label_idx=1,label:size(2) do
		local x=label[1][label_idx]
		-- math.floor(label[1][label_idx]);
		local y=label[2][label_idx]
		print ('label_idx',label_idx,x,y)
		if x>210 then
			x=210;
		end
		if x<0 then
			x=1;
		end
		if y>210 then
			y=210;
		end
		if y<0 then
			y=1;
		end
		
		-- math.floor(label[2][label_idx]);
		-- im[1][x][y]=0.0
		-- im[2][x][y]=1.0
		-- im[3][x][y]=0.0
		im=image.drawText(im,"X",y,x,{color=colors[label_idx]})
	end
	-- print (im:size())
	image.save(out_file,im);	
end



function getBatchPoints(td)
	local horse_labels={};
	local human_labels={};

	for idx_curr=1,td.training_set_horse.label:size(1) do
		local label_curr_horse = td.training_set_horse.label[idx_curr];
		local label_curr_human=td.training_set_human.label[idx_curr];
		local keep_col=label_curr_horse[{{},3}]:gt(0)+label_curr_human[{{},3}]:gt(0)
		local idx_keep=torch.find(keep_col:gt(1), 1)
		-- local idx_keep=torch.find(label_curr_horse[{{},3}]:gt(0), 1)

		local label_curr_pos_horse=torch.zeros(#idx_keep,2):type(label_curr_horse:type());
		for idx_pos=1,#idx_keep do
			label_curr_pos_horse[idx_pos]=label_curr_horse[{idx_keep[idx_pos],{1,2}}];
		end

		
		local label_curr_pos_human=torch.zeros(#idx_keep,2):type(label_curr_human:type());
		for idx_pos=1,#idx_keep do
			label_curr_pos_human[idx_pos]=label_curr_human[{idx_keep[idx_pos],{1,2}}];
		end
		assert (label_curr_pos_human:size(1)==label_curr_pos_horse:size(1));
		horse_labels[idx_curr]=label_curr_pos_horse:t();
		human_labels[idx_curr]=label_curr_pos_human:t();
	end
	assert (#horse_labels==#human_labels)
	return horse_labels,human_labels;
end



function getLossD(pred_output,gt_output)
	-- print ('pred_output',pred_output:size());
	-- print ('gt_output',gt_output:size());

	local lossD=pred_output-gt_output
	lossD=torch.mul(lossD,2);
	-- print (torch.mean(lossD));
	return lossD;
end

function getLoss(pred_output,gt_output)
	local loss=torch.pow(pred_output-gt_output,2);
	loss=torch.mean(loss);
	return loss;
end

local fevalScore = function(x)
    if x ~= parameters then
	    parameters:copy(x)
    end
    
    local batch_inputs = td.training_set_horse.data:clone():cuda();
    local batch_targets = gt_output:clone():cuda();
    
    gradParameters:zero()
 --    if dest_flag then
	-- 	batch_inputs = dest_offsets:clone();
	-- end

    local outputs=locnet:forward(batch_inputs);
    local dloss = getLossD(outputs,batch_targets);
    local loss = getLoss(outputs,batch_targets);

    locnet:backward(batch_inputs, dloss)
    -- local in_curr=locnet:get(2).output;
    -- print ('in_curr',in_curr:size())
    -- print ('dloss',dloss:size());
    -- local grad_in=locnet:get(21):backward(in_curr,dloss);
    -- print ('grad_in',grad_in:size());
    
    return loss, gradParameters;
end




-- horse_path='/home/SSD3/maheen-data/horse_data/train_10.txt'
-- human_path='/home/SSD3/maheen-data/face_data/train_10.txt'

-- horse_path='/home/SSD3/maheen-data/horse_project/horse/matches_5.txt'
-- human_path='/home/SSD3/maheen-data/horse_project/aflw/matches_noIm_5.txt'
horse_path='/home/SSD3/maheen-data/horse_project/horse/matches_5_train_fiveKP.txt'
human_path='/home/SSD3/maheen-data/horse_project/aflw/matches_5_train_fiveKP.txt'

horse_path='/home/SSD3/maheen-data/horse_project/horse/matches_5_val_fiveKP.txt'
human_path='/home/SSD3/maheen-data/horse_project/aflw/matches_5_val_fiveKP.txt'
humanImage=true;

-- human_path='/home/SSD3/maheen-data/horse_project/aflw/matches_5_train_fiveKP_noIm.txt'
-- humanImage=false;

out_dir='/home/SSD3/maheen-data/temp/horse_human';
out_dir=paths.concat(out_dir,'viz_transform_aflw_val');
alexnet_modified_file='/home/SSD3/maheen-data/horse_project/models/conv5_2fc_closeToZero.dat';
paths.mkdir(out_dir);
num_ctrl_pts=36;
max_iter=120;
size_out=224;
size_out_conv=34;

paths.mkdir(out_dir);

td=data({file_path_horse=horse_path,file_path_human=human_path,limit=10,humanImage=humanImage});
td.batch_size=10;
td.augmentaion=false;
td.params.input_size={size_out,size_out};
-- td.humanImage=true;
td:getTrainingData();

print (td.training_set_horse.data:size());
print (td.training_set_horse.label:size());
print (td.training_set_human.label:size());
print (td.training_set_human.data:size())

-- td.training_set_human.data=torch.zeros(td.training_set_horse.data:size());
-- print (td.training_set_human.data);
td.training_set_horse.data=td.training_set_horse.data:cuda();
td.training_set_human.data=td.training_set_human.data:cuda();
td.training_set_human.label=td.training_set_human.label:cuda();
td.training_set_horse.label=td.training_set_horse.label:cuda();

horse_labels,human_labels=getBatchPoints(td)

tps=nn.TPSGridGeneratorBHWD(num_ctrl_pts,size_out,size_out):cuda();

timer=torch.Timer();
gt_output=tps:getGTOutput(human_labels,horse_labels);
print('time 152 gt_output ' .. timer:time().real .. ' seconds')
timer:reset();
print('time 152 gt_output ' .. timer:time().real .. ' seconds')



-- td.training_set_horse.data=td.training_set_horse.data:double();
-- td.training_set_human.data=td.training_set_human.data:double();
-- td.training_set_human.label=td.training_set_human.label:double();
-- td.training_set_horse.label=td.training_set_horse.label:double();
-- gt_output=gt_output:double();
data_org=td.training_set_horse.data;
print (data_org:type());
k=nn.Transpose({2,3},{3,4}):cuda();
data=k:forward(data_org);

x=nn.BilinearSamplerBHWD():cuda()
x:forward({data,gt_output});
paths.mkdir(out_dir);

for i=1,data_org:size(1) do
	-- print ('im_no',i);
    -- local im=x.output[{i,{},{},1}]:clone():view(1,224,224)/255;
    out_file_horse=paths.concat(out_dir,i..'_horse.jpg');
    -- print (horse_labels[i]:size());
    saveImageAndAnno(out_file_horse,td.training_set_horse.data[i]:double(),horse_labels[i]:t():double(),td.params.mean);
    	-- td.training_set_horse.label[i],td.params.mean);

    out_file_human=paths.concat(out_dir,i..'_human.jpg');
    
    saveImageAndAnno(out_file_human,td.training_set_human.data[i]:double(),human_labels[i]:t():double(),td.params.mean);
    	-- td.training_set_human.label[i],td.params.mean);

    -- print (horse_labels[i]:size())
    local im = x.output[i]:transpose(1,3):transpose(2,3)
    for idx_rgb=1,3 do
    	im[idx_rgb]=im[idx_rgb]+td.params.mean[idx_rgb];
    end
    im=im/255;

    local out_file_curr=paths.concat(out_dir,i..'_gt.jpg');
    image.save(out_file_curr,im);
    -- print (out_file_curr,horse_labels[i]:size(2));
end



-- skdjlaksdjlsakjdlaksjdlkasjdlkajsldkjasljd
-- locnet = nn.Sequential()

-- locnet:add(cudnn.SpatialMaxPooling(2,2,2,2))
-- locnet:add(cudnn.SpatialConvolution(3,20,5,5))
-- locnet:add(cudnn.ReLU(true))
-- locnet:add(cudnn.SpatialMaxPooling(2,2,2,2))
-- locnet:add(cudnn.SpatialConvolution(20,20,5,5))
-- locnet:add(cudnn.ReLU(true))
-- locnet:add(nn.View(20*size_out_conv*size_out_conv))
-- locnet:add(nn.Linear(20*size_out_conv*size_out_conv,40))
-- locnet:add(cudnn.ReLU(true))

-- -- -- we initialize the output layer so it gives the identity transform
-- local outLayer = nn.Linear(40,2*num_ctrl_pts)
-- outLayer.weight:fill(0)
-- local bias = torch.FloatTensor(2*num_ctrl_pts):fill(0)
-- outLayer.bias:copy(bias)
-- locnet:add(outLayer)
-- there we generate the grids
-- locnet:add(nn.TPSGridGeneratorBHWD(num_ctrl_pts,size_out,size_out));
-- timer:reset();
-- locnet=torch.load(alexnet_modified_file);
-- print('time 216 load ' .. timer:time().real .. ' seconds')
-- print (locnet);
-- locnet:get(22).weight=torch.zeros(locnet:get(22).weight:size()):type(locnet:get(22).weight:type());
-- locnet:get(22).bias=torch.zeros(locnet:get(22).bias:size()):type(locnet:get(22).bias:type());
-- -- locnet:add(nn.Tanh());

-- locnet:add(nn.TPSGridGeneratorBHWD(num_ctrl_pts,size_out,size_out));
-- print('time 222 add ' .. timer:time().real .. ' seconds')
-- -- -- if dest_flag then
-- -- -- 	locnet = nn.Sequential();
-- -- -- 	locnet:add(nn.TPSGridGeneratorBHWD(num_ctrl_pts,32,32));
-- -- -- end
-- timer:reset();
-- locnet:cuda();
-- print('time 230 cuda ' .. timer:time().real .. ' seconds')
-- print (locnet);
-- -- output=locnet:forward(td.training_set_horse.data:cuda());
-- -- print (output:size())

-- td.training_set_horse.data=td.training_set_horse.data:cuda();
-- td.training_set_human.data=td.training_set_human.data:cuda();
-- td.training_set_human.label=td.training_set_human.label:cuda();
-- td.training_set_horse.label=td.training_set_horse.label:cuda();

-- parameters, gradParameters = locnet:getParameters()

-- optimState = {learningRate = 0.00001, momentum = 0.9, weightDecay = 5e-4}
-- optimMethod = optim.sgd

-- for i=1,max_iter do

-- 	local _, minibatch_loss = optimMethod(fevalScore,parameters, optimState)
-- 	-- print (minibatch_loss[1]:size());
-- 	-- print (i,torch.mean(minibatch_loss[1]))
-- 	print(string.format("minibatches processed: %6s, loss = %6.6f", i, minibatch_loss[1]));
    
-- end

-- -- locnet=torch.load('/home/SSD3/maheen-data/temp/horse_human_test_tps/final/model_all_final.dat');
-- print (torch.max(locnet:get(22).weight),torch.min(locnet:get(22).weight));
-- print (torch.max(locnet:get(19).weight),torch.min(locnet:get(19).weight));
-- print (torch.max(locnet:get(15).weight),torch.min(locnet:get(15).weight));
-- torch.save('model_temp.dat',locnet);

-- locnet=torch.load('model_temp.dat');
locnet=torch.load('/home/SSD3/maheen-data/horse_human_fiveKP/intermediate/model_all_1500.dat');
local out_grids=locnet:forward(td.training_set_horse.data);	
print (out_grids:size());
print (torch.min(horse_labels[1]),torch.max(horse_labels[1]),torch.min(out_grids[1]),torch.max(out_grids[1]));
t_pts_all={};
for i=1,out_grids:size(1) do
	local grid_curr=out_grids[i];
	local labels=td.training_set_horse.label[i];
	local t_pts_curr=torch.zeros(labels:size(1),2):type(labels:type());
	for label_idx=1,labels:size(1) do
		local label_curr=labels[{label_idx,{1,2}}];
		label_curr=label_curr:view(1,1,2);
		label_curr=torch.repeatTensor(label_curr,grid_curr:size(1),grid_curr:size(2),1);
		-- print ('____');
		-- print (label_curr:size());
		-- print (grid_curr:size());
		-- print (torch.min(label_curr:select(3,1)),torch.max(label_curr:select(3,1)))
		-- print (torch.min(label_curr:select(3,2)),torch.max(label_curr:select(3,2)))

		local dist=torch.sum(torch.pow(grid_curr-label_curr,2),3);
		dist=dist:view(dist:size(1),dist:size(2));
		local idx=torch.find(dist:eq(torch.min(dist)),1)[1]
		local row = math.ceil(idx/dist:size(2));
		local col = idx%dist:size(2);
		if col==0 then
			col=dist:size(2);
		end
		



		-- print (dist:size())
		-- dist=dist:view(dist:size(1),dist:size(2));
		-- local min_val=torch.min(dist);
		-- print (torch.find(dist==min_val))

		-- print (min_val);
		-- print (dist:type())

		-- local val_x = torch.min(dist,1);
		-- -- print (val_x:size(),val_x:type());
		-- -- print (torch.find(val_x:view(val_x:nElement()):eq(min_val)));
		-- local val_c, c=torch.min(torch.abs(val_x-min_val),1);
		-- local val_y=torch.min(dist,2);
		-- local val_r,r=torch.min(torch.abs(val_y-min_val),1)
		-- print (val_c,val_r)
		-- print (c,r);
		t_pts_curr[label_idx][1]=row;
		t_pts_curr[label_idx][2]=col;

	end
	-- print (t_pts_curr);

	t_pts_all[#t_pts_all+1] = t_pts_curr;


-- print (locnet:get(#locnet))
-- print (locnet:get(#locnet).coefficients:size())
-- t_pts_all={}
-- for i=1,#horse_labels do

-- 	local t_pts=locnet:get(#locnet):updateOutputSpecific(horse_labels[i]:cuda(),i);
-- 	-- print (horse_labels[i]:size());
-- 	-- print (t_pts:size());
-- 	t_pts_all[i]=t_pts:double();
end




local net_out=nn.Sequential();
local trans = nn.Transpose({2,3},{3,4}):cuda();

local data=trans:forward(td.training_set_horse.data:cuda());
local bil=nn.BilinearSamplerBHWD():cuda();

bil:forward({data,out_grids});


for i=1,10 do
    local im = bil.output[i]:transpose(1,3):transpose(2,3):double();
    local out_file_curr=paths.concat(out_dir,i..'_t.jpg');
    print (t_pts_all[i]:size())
    saveImageAndAnno(out_file_curr,im,t_pts_all[i],td.params.mean,true)



    -- for idx_rgb=1,3 do
    -- 	im[idx_rgb]=im[idx_rgb]+td.params.mean[idx_rgb];
    -- end
    -- im=im/255;

    -- local out_file_curr=paths.concat(out_dir,i..'_t.jpg');
    -- image.save(out_file_curr,im);
end
